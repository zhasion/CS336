device: cuda
logger: tensorboard
ablation: norms

model:
  vocab_size: 10000
  context_length: 256
  d_model: 512
  num_layers: 4
  num_heads: 16
  d_ff: 1344
  rope_theta: 10000


optimizer:
  max_lr: 0.0002
  min_lr: 0
  warmup_iters: 50
  cosine_cycle_iters: 10000
  betas: [0.9, 0.95]
  max_l2_norm: 10
  weight_decay: 0.01


trainer:
  max_iteration: 10000 # max_iteration * batchs_size = 1280000
  batch_size: 128
  print_frequency: 10
  val_frequency: 10
  save_frequency: 10001


data:
  train_path: 'data/TinyStoriesV2-GPT4-train.npz'
  val_path: 'data/TinyStoriesV2-GPT4-valid.npz'


tokenizer:
  vocab_path: 'output/tinystories_vocab.pkl'
  merges_path: 'output/tinystories_merges.pkl'