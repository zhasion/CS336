device: cuda
logger: tensorboard

model:
  vocab_size: 10000
  context_length: 256
  d_model: 512
  num_layers: 4
  num_heads: 16
  d_ff: 1344
  rope_theta: 10000


optimizer:
  max_lr: 0.005
  min_lr: 0
  warmup_iters: 100
  cosine_cycle_iters: 20000
  betas: [0.9, 0.95]
  max_l2_norm: 10
  weight_decay: 0.01


trainer:
  max_iteration: 20000 # max_iteration * batchs_size * context_length = 1280000 * 256
  batch_size: 64
  print_frequency: 20
  val_frequency: 20
  save_frequency: 20001


data:
  train_path: 'data/TinyStoriesV2-GPT4-train.npz'
  val_path: 'data/TinyStoriesV2-GPT4-valid.npz'


tokenizer:
  vocab_path: 'output/tinystories_vocab.pkl'
  merges_path: 'output/tinystories_merges.pkl'