device: cuda
logger: tensorboard

model:
  vocab_size: 32_000
  context_length: 256
  d_model: 512
  num_layers: 4
  num_heads: 16
  d_ff: 1344
  rope_theta: 10000


optimizer:
  max_lr: 0.002
  min_lr: 0.0001
  warmup_iters: 50
  cosine_cycle_iters: 10000
  betas: [0.9, 0.95]
  max_l2_norm: 10
  weight_decay: 0.01


trainer:
  max_iteration: 20000 # max_iteration * batchs_size = 1280000
  batch_size: 64
  print_frequency: 10
  val_frequency: 10
  save_frequency: 20000


data:
  train_path: 'data/owt_train.npz'
  val_path: 'data/owt_valid.npz'


tokenizer:
  vocab_path: 'output/owt_vocab.pkl'
  merges_path: 'output/owt_merges.pkl'